---
layout: default
title: CV 
permalink: /CV/
---

# CV - Logan Thomson

[<i class="fa-solid fa-envelope"></i> logan@loganthomson.com](mailto:logan@loganthomson.com) \| [<i class="fa-brands fa-github"></i> github.com/xycoord](https://github.com/xycoord) \| [<i class="fa-solid fa-globe"></i> loganthomson.com](loganthomson.com)


## Technical Skills

Core ML Engineering:
- **Python** [Projects 1,2,3,4,5,6]
- **PyTorch** [Projects 1,2,4,5,6]
- **ML Experimentation** [Projects 1,2,4,5,6]  
  Experiment design, hyperparameter tuning, debugging training

Specialised Expertise:
- **Transformers and Language Models** [Project 1]
- **Reinforcement Learning** [Projects 2,6]  
  Focus on policy gradient algorithms & PPO
- **Algorithm Optimisation** [Project 3]

Active Exploration:
- **Mechanistic Interpretability** [Project 4]

Research Skills:
- **Technical Writing** [Projects 1,2,3]  
  Clear explanations of complex topics (blog posts, teaching materials)
- **Paper Re-implementation** [Projects 1,2,4,5,6]
- **Mathematical Rigor** [Projects 1,2]


## Projects

All independently designed and implemented:

1. **Transformer Language Model** [[GitHub]](https://github.com/xycoord/Language-Modelling/)  
  From-scratch PyTorch implementation with KV caching and RoPE [[Blog Post]](https://loganthomson.com/RoPE/).  
  Modular architecture emphasising code clarity and understanding.  

2. **Reinforcement Learning Course** [[Part 1]](https://colab.research.google.com/drive/1Lm_TI-Vrzai-WZQeZL3o7US07vVKWXlQ) [[Part 2]](https://colab.research.google.com/drive/1UULTQYnymQOpa7nuaw6mDXnvWRV9R_2y)  
  Teaching RL through rigorous mathematical derivations and implementations from first principles.  

3. **BPE Tokeniser** [[GitHub]](https://github.com/xycoord/Language-Modelling/tree/main/src/lm_tokenizers) [[Blog Post]](https://loganthomson.com/Optimising-BPE/)  
  Optimised training implementation (hours â†’ 13s) with systematic profiling.  

4. **Mechanistic Interpretability** [[GitHub]](https://github.com/xycoord/Language-Modelling/tree/main/src/mech_interp)  
  Reproduced "Toy Models of Superposition" experiments and trained SAEs (ReLU, TopK, BatchTopK) to extract their learnt features.  

5. **Masters Research Project** (Supervised by Ronald Clark) [[GitHub]](https://github.com/xycoord/Transparency-Segmentation) [[Report]](https://drive.google.com/file/d/1BvU4-v3jf7onxT1T6RyVTEVyawAkavyV/view?usp=drive_link)  
  Fine-tuned diffusion models for image segmentation of transparent objects.  
  Implemented and evaluated NeRF methods which learn how light bends in a scene.  

6. **PPO Implementation** [[GitHub]](https://github.com/xycoord/PPO)  
  From-scratch PPO agent featuring key modern techniques, such as GAE and vectorised environments.

Active interest in AI safety research, particularly mechanistic interpretability approaches.

## Team Experience
**Co-founder at [[The Grove]](https://thegrovenotts.co.uk)**, 2024
- Collaboratively designed and built recording studio/music venue to high technical standards.
- Translated technical requirements (e.g. fire safety regulations, acoustic design) into actionable tasks for team.
- Successfully built thriving community space; exited to focus on AI safety

## Education

Oxford University, 2020-2024  
Masters in Computer Science and Philosophy (MCompPhil)  
*First Class*

Relevant Courses -
***Ethics of AI**,
Computer Vision,
Geometric Deep Learning,
Machine Learning,
Ethics,
Philosophy of Mind,
Philosophy of Cognitive Science,
Law and Computer Science,
Computers in Society*